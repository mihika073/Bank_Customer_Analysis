{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihika073/Bank_Customer_Analysis/blob/master/Assignment2_FFNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsBiuoind7a_"
      },
      "source": [
        "# Assignment 2: Trainable Parms and NN Regression (DL)\n",
        "**Dr. Dave Wanik - University of Connecticut**\n",
        "\n",
        "-----------------------------------------------\n",
        "* Student Full Name: YOUR NAME HERE\n",
        "* Student ID (7 digit number): 1234567\n",
        "\n",
        "\n",
        "Let's cover some theory and application of neural networks for regression! In Q1 you will count trainable parameters. In Q2 you will read in real-world data and build, fit and evaluate a model!\n",
        "\n",
        "Students may work with their fellow classmates to complete the assignment, but each student must do their own work (i.e. write their own math and submit their own assignment for grading.) If I find that notebooks look like direct copying (i.e. copying comments and code snippets), the students involved get a 0 on the assignment. **Do your own work!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (50 points) **Q1.** Recreate the math in the `model.summmary()` below\n",
        "\n",
        "First, let's make sure you understand the concept of weights and biases. \n",
        "\n",
        "Imagine that your data set has 20,000 rows and 50 columns. You are to count the trainable parameters and show the output shape for each layer in the network (update `ABCDEFG` below using your own StudentID). \n",
        "\n",
        "**Note: if you have a 0 in your student ID, please recode it to a $5$ so that the math works out!**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kAlSVzPxP_ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________\n",
        "## Rubric\n",
        "Recreate the model summary above using the outputs from your own 7 digit student ID.\n",
        "\n",
        "To get full credit, no mathematical errors, correct number of weights and biases and specified, all LaTex equations are correct; bullets for each calculation are accurate and detailed enough to demonstrate mastery of the material."
      ],
      "metadata": {
        "id": "TZ5Cfh8aQiaR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZYAnICAQiPp"
      },
      "source": [
        "# leave this as 50 for now\n",
        "n_features = 50\n",
        "\n",
        "# put your 7 digit Student ID, replace the 1234567\n",
        "# if you have a 0 in your studentID, please replace it with a 5 (so the math works out!)\n",
        "A = 1\n",
        "B = 2\n",
        "C = 3\n",
        "D = 4\n",
        "E = 5\n",
        "F = 6\n",
        "G = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pppd5U01d4hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d198d9c-0f3f-403e-830e-840a4c2108dc"
      },
      "source": [
        "# now run this code\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(A, activation='relu', input_shape=(n_features,))) # see how we didnt hard code a 50 here?\n",
        "model.add(Dense(B, activation='relu'))\n",
        "model.add(Dense(C, activation='relu'))\n",
        "model.add(Dense(D, activation='relu'))\n",
        "model.add(Dense(E, activation='relu'))\n",
        "model.add(Dense(F, activation='relu'))\n",
        "model.add(Dense(G, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 4         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 9         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 16        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 25        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 36        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 49        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198\n",
            "Trainable params: 198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure you add a nice subheader for each layer in the network!"
      ],
      "metadata": {
        "id": "FPE1MYBRRtlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer `dense` (51 trainable parameters, 50 weights, 1 bias)\n",
        "50 weights and 1 bias. There are 50 inputs going into a hidden layer with 1 hidden unit, and there is 1 bias for each of the 1 hidden units in the layer."
      ],
      "metadata": {
        "id": "t5DNU6iumzoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Double click this cell to see how to make math equations with $\\LaTeX$ formatting!**\n",
        "\n",
        "$50*1 + 1 = 51$"
      ],
      "metadata": {
        "id": "rn4_hKkumcsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (50 points) **Q2.** Fit and evaluate a model using real-world data\n",
        "I gave you (mostly) clean data to work with ðŸ˜ƒ\n",
        "These are hourly observations of weather vs. energy (electricity) consumption in New England. This is a real-world dataset you can brag about on your resume when you apply to jobs.\n"
      ],
      "metadata": {
        "id": "vS5xAhibRnOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rubric\n",
        "Make sure you use lots of subheaders, comments and text narrative cells so that it's easy to grade - otherwise, points off!\n",
        "\n",
        "**Prep the data (10 points):**\n",
        "* Read the energy/weather data: https://drive.google.com/file/d/1ylQJKeCyMStvvMzRGDo8nR1TI8_3xGgP/view?usp=sharing\n",
        "* Select columns for modeling\n",
        "  * Check for missing values and inspect data types\n",
        "  * The target variable is last column df['MWh']\n",
        "  * You can use as many columns for X, but you may want to just stick to df['tmpf'] through `df['sknt']` along with the df['HE'] (which is the hour of the day).\n",
        "    * A data dictionary for the weather data can be found at the bottom of this website: https://mesonet.agron.iastate.edu/request/download.phtml\n",
        "  * If you want to be an overachiever (and I think you should!), feel free to do some feature engineering (but this is optional)\n",
        ".\n",
        "* Use an 80/20 train/val split\n",
        "* Apply min/max or standard scalar to X_train and apply to X_test\n",
        "\n",
        "\n",
        "**Build, compile and fit a model (20 points)**\n",
        "* Use as many or as few layers as you would like, with as many or as few hidden units as you would like.\n",
        "* You must use  dropout and early stopping (make sure you return the best weights, you can choose what value of patience to use.)\n",
        "  * Here are some hints and a nice example of using dropout - values between 0.2 and 0.5 work well. https://machinelearningknowledge.ai/keras-dropout-layer-explained-for-beginners/\n",
        "\n",
        "**Evaluate the model (20 points):**\n",
        "* Make a learning curve for train and validation loss\n",
        "* Create a scatterplot of actual vs. predicted for each partition\n",
        "* Calculate MAE, RMSE and R2 for each partition.\n",
        "* Write five bullets about how your experience went - for example: Did you try many different architectures or did you just get lucky on your first try?  Were you nervous or excited to build your first model on real-world data. How did you ensure your model didn't overfit or underfit? Any weird patterns in the scatterplot or error metrics? Be thoughtful here."
      ],
      "metadata": {
        "id": "Tzpo25NPiL8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# have fun! Use lots of subheaders and comments and make something that you are proud of"
      ],
      "metadata": {
        "id": "2UYmlOjNetyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}